import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import DataLoader, random_split
import numpy as np
import pandas as pd
import torch.optim as optim
import time
device1 = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')
print(device1)
import os
os.environ['KMP_DUPLICATE_LIB_OK']='TRUE'

#slice both training data and label data into non-overlapping segments of a specified length .
#It also handles compensating for any length differences in the first and last segments to ensure they have the same length.
def slice_data_label(list_line, list_line_label, slice_window_long=300, initial_site=0):
    """
    list_line   A list containing the training data, which will be sliced into smaller segments.
    list_line_label   A list containing the corresponding labels for the training data, which will also be sliced in the same way.
    slice_window_long = 300   The length of each segment (window) into which the training data and labels will be divided. Default is 300.
    initial_site = 0   The starting index for slicing the data. Default is 0, meaning the slicing will start from the beginning of the data.
    """
    window_data_line = []
    for i in range(int(len(list_line) / slice_window_long) + 1):
        start_index = initial_site + i * slice_window_long
        end_index = initial_site + (i + 1) * slice_window_long
        pian = list_line[max(start_index, 0):min(end_index, len(list_line))]
        window_data_line.append(pian)
        if len(window_data_line[0]) != slice_window_long:
            window_data_line[0] = [list_line[0]] * (slice_window_long - len(window_data_line[0])) + list(
                window_data_line[0])
        if len(window_data_line[-1]) != slice_window_long:
            window_data_line[-1] = list(window_data_line[-1]) + [list_line[-1]] * (
                    slice_window_long - len(window_data_line[-1]))
    window_data_line_label = []
    for i in range(int(len(list_line_label) / slice_window_long) + 1):
        start_index = initial_site + i * slice_window_long
        end_index = initial_site + (i + 1) * slice_window_long
        pian = list_line_label[max(start_index, 0):min(end_index, len(list_line))]
        window_data_line_label.append(pian)
        if len(window_data_line_label[0]) != slice_window_long:
            window_data_line_label[0] = [list_line[0]] * (slice_window_long - len(window_data_line_label[0])) + list(
                window_data_line_label[0])
        if len(window_data_line_label[-1]) != slice_window_long:
            window_data_line_label[-1] = list(window_data_line_label[-1]) + [list_line[-1]] * (
                    slice_window_long - len(window_data_line_label[-1]))
    return window_data_line, window_data_line_label  # Return two lists: one containing the sliced training data (each slice of length 300) and the other containing the corresponding label data slices (also of length 300).


def get_formatted_time(seconds):  # Function to convert seconds into a formatted time string (HH:MM:SS)
    hours = round(seconds // 3600)
    minutes = round((seconds % 3600) // 60)

    seconds = round(seconds % 60)
    return f'{hours:02}:{minutes:02}:{seconds:02}'  # Return the formatted time as a string in HH:MM:SS format

#max_min_normalize
def max_min_normalize(sample_data, sample_label):
    re_data_noise_list = []  # Temporary list to store processed noisy distance slices
    re_data_list = []  # Temporary list to store processed clean distance slices

    for signal1, signal2 in zip(sample_data, sample_label):
        mean_signal = np.mean(signal1)
        min_signal = np.min(signal1)
        max_signal = np.max(signal1)
        max_min_signal = max_signal - min_signal

        if max_min_signal == 0:
            data_f_re1 = signal1 - mean_signal
            label_f_re2 = signal2 - mean_signal
        else:
            data_f_re1 = 2 * (signal1 - mean_signal) / max_min_signal
            label_f_re2 = 2 * (signal2 - mean_signal) / max_min_signal

        re_data_noise_list.append(data_f_re1)
        re_data_list.append(label_f_re2)

    return re_data_noise_list, re_data_list

#Perform sliding slicing and normalization preprocessing on the data generated by the simulation model.
# Here, data_in is the input data, sample_long is the length of each element, and downsample_rate is the downsampling rate applied to the data.
def data_proceeding(data_in, sample_long=2000, downsample_rate=1):
    data = np.array(data_in, dtype='float')[::downsample_rate]  # Downsample the input data with the specified rate
    force_noise = data[:, 0:1 * sample_long]  # Extract the noisy force signal (first segment of the data)
    distance_noise = data[:, 1 * sample_long:2 * sample_long]  # Extract the noisy distance signal (second segment)
    force = data[:, 2 * sample_long:3 * sample_long]  # Extract the clean force signal (third segment)
    distance = data[:, 3 * sample_long:4 * sample_long]  # Extract the clean distance signal (fourth segment)
    label_4000_4045 = data[:,4 * sample_long:4 * sample_long + 45]  # Extract other parameters (label for force, distance, etc.)

    fold_num = label_4000_4045[:, 0]  # Extract the fold number from the label data
    force1 = label_4000_4045[:, 1:7]  # Extract the force data for site 1
    force2 = label_4000_4045[:, 7:13]  # Extract the force data for site 2
    distance1 = label_4000_4045[:, 13:19]  # Extract the distance data for site 1
    distance2 = label_4000_4045[:, 19:25]  # Extract the distance data for site 2
    fold_size_list = label_4000_4045[:, 25:31]  # Extract the fold structure size
    P_list = label_4000_4045[:, 31:38]  # Extract the holding length parameters
    L_list = label_4000_4045[:, 38:45]  # Extract the contour length parameters

    re_force_noise = []  # Initialize list for normalized noisy force data
    re_distance_noise = []  # Initialize list for normalized noisy distance data
    re_force = []  # Initialize list for normalized clean force data
    re_distance = []  # Initialize list for normalized clean distance data
    slice_window_size = 300  # Define the slicing window length for the data

    # Loop through each force and distance data to slice and normalize
    for i in range(len(force_noise)):
        initial_site = np.random.randint(-int(slice_window_size / 4), 0)  # Randomly set initial site for slicing

        # Slice and process noisy force and distance signals
        #slice
        sample_data_f, sample_label_f = slice_data_label(list_line=force_noise[i], list_line_label=force[i],
                                                         slice_window_long=slice_window_size,
                                                         initial_site=initial_site)
        sample_data_d, sample_label_d = slice_data_label(list_line=distance_noise[i], list_line_label=distance[i],
                                                         slice_window_long=slice_window_size,
                                                         initial_site=initial_site)
        #normalization
        re_force_noise_list,re_force_list=max_min_normalize(sample_data=sample_data_f, sample_label=sample_label_f)
        re_distance_noise_list,re_distance_list=max_min_normalize(sample_data=sample_data_d, sample_label=sample_label_d)

        re_force_noise.append(re_force_noise_list)  # Add processed noisy force slices
        re_distance_noise.append(re_distance_noise_list)  # Add processed noisy distance slices
        re_force.append(re_force_list)  # Add processed clean force slices
        re_distance.append(re_distance_list)  # Add processed clean distance slices

    # Convert lists to numpy arrays
    re_force_noise = np.array([item for sublist in re_force_noise for item in sublist])
    re_distance_noise = np.array([item for sublist in re_distance_noise for item in sublist])
    re_force = np.array([item for sublist in re_force for item in sublist])
    re_distance = np.array([item for sublist in re_distance for item in sublist])

    # Reshape the data for concatenation
    re_force_noise = re_force_noise.reshape(re_force_noise.shape[0], 1, re_force_noise.shape[1])
    re_distance_noise = re_distance_noise.reshape(re_distance_noise.shape[0], 1, re_distance_noise.shape[1])

    # Concatenate noisy force and noisy distance data
    data_normalization_re = np.concatenate((
        re_force_noise,
        re_distance_noise,
    ), axis=1)

    # Reshape clean force and clean distance data
    re_force = re_force.reshape(re_force.shape[0], 1, re_force.shape[1])
    re_distance = re_distance.reshape(re_distance.shape[0], 1, re_distance.shape[1])

    # Concatenate clean force and clean distance data
    label_normalization_re = np.concatenate((
        re_force,
        re_distance
    ), axis=1)

    #Reverse the data to perform data augmentation############
    data = np.array(data_in, dtype='float')[::downsample_rate]
    force_noise = data[:, 0:1 * sample_long][:, ::-1]
    distance_noise = data[:, 1 * sample_long:2 * sample_long][:, ::-1]
    force = data[:, 2 * sample_long:3 * sample_long][:, ::-1]
    distance = data[:, 3 * sample_long:4 * sample_long][:, ::-1]

    re_force_noise = []
    re_distance_noise = []
    re_force = []
    re_distance = []
    for i in range(len(force_noise)):
        # if i % 1000 == 0:
        #     print(i)
        initial_site = np.random.randint(-int(slice_window_size / 4), 0)
        sample_data_f, sample_label_f = slice_data_label(list_line=force_noise[i], list_line_label=force[i],
                                                         slice_window_long=slice_window_size,
                                                         initial_site=initial_site)
        sample_data_d, sample_label_d = slice_data_label(list_line=distance_noise[i], list_line_label=distance[i],
                                                         slice_window_long=slice_window_size,
                                                         initial_site=initial_site)

        #normalization
        re_force_noise_list,re_force_list=max_min_normalize(sample_data=sample_data_f, sample_label=sample_label_f)
        re_distance_noise_list,re_distance_list=max_min_normalize(sample_data=sample_data_d, sample_label=sample_label_d)

        re_force_noise.append(re_force_noise_list)
        re_distance_noise.append(re_distance_noise_list)
        re_force.append(re_force_list)
        re_distance.append(re_distance_list)
    re_force_noise = np.array([item for sublist in re_force_noise for item in sublist])
    re_distance_noise = np.array([item for sublist in re_distance_noise for item in sublist])
    re_force = np.array([item for sublist in re_force for item in sublist])
    re_distance = np.array([item for sublist in re_distance for item in sublist])



    re_force_noise = re_force_noise.reshape(re_force_noise.shape[0], 1, re_force_noise.shape[1])
    re_distance_noise = re_distance_noise.reshape(re_distance_noise.shape[0], 1, re_distance_noise.shape[1])
    data_normalization_augment = np.concatenate((
        re_force_noise,
        re_distance_noise,
    ), axis=1)

    re_force = re_force.reshape(re_force.shape[0], 1, re_force.shape[1])
    re_distance = re_distance.reshape(re_distance.shape[0], 1, re_distance.shape[1])

    label_normalization_augment = np.concatenate((
        re_force,
        re_distance
    ), axis=1)

    data_normalization_augment_all = np.concatenate((
        data_normalization_re,  # The first dataset, which contains the normalized data
        data_normalization_augment,  # The second dataset, which contains augmented data
    ), axis=0)  # Concatenate both datasets along the first axis, combining them into one larger dataset

    label_normalization_augment_all = np.concatenate((
        label_normalization_re,  # The first set of labels, corresponding to the normalized data
        label_normalization_augment,  # The second set of labels, corresponding to the augmented data
    ), axis=0)  # Concatenate the labels along the first axis, combining them into one larger label dataset

    return data_normalization_augment_all, label_normalization_augment_all

# denoising model
# Define the SelfAttention class as a subclass of nn.Module
class SelfAttention(nn.Module):
    def __init__(self, in_channels):
        super(SelfAttention, self).__init__()
        self.query = nn.Conv1d(in_channels, in_channels // 8, kernel_size=1)
        self.key = nn.Conv1d(in_channels, in_channels // 8, kernel_size=1)
        self.value = nn.Conv1d(in_channels, in_channels, kernel_size=1)
        self.gamma = nn.Parameter(torch.zeros(1))

    def forward(self, x):
        batch_size, C, T = x.size()
        query = self.query(x).view(batch_size, -1, T).permute(0, 2, 1)
        key = self.key(x).view(batch_size, -1, T)
        attention = torch.bmm(query, key)
        attention = F.softmax(attention, dim=-1)
        value = self.value(x).view(batch_size, -1, T)
        out = torch.bmm(value, attention.permute(0, 2, 1))
        out = out.view(batch_size, C, T)
        out = self.gamma * out + x
        return out

# Define the InceptionBlock class as a subclass of nn.Module
class InceptionBlock(nn.Module):
    def __init__(self, in_channels, hid_channels, kernel_size=[59, 29, 15, 7]):
        super(InceptionBlock, self).__init__()
        self.branch1 = nn.Conv1d(in_channels, hid_channels, kernel_size=1, stride=1)
        self.branch2 = nn.Conv1d(hid_channels, hid_channels, kernel_size=kernel_size[0], stride=1,
                                 padding=kernel_size[0] // 2)
        self.branch3 = nn.Conv1d(hid_channels, hid_channels, kernel_size=kernel_size[1], stride=1,
                                 padding=kernel_size[1] // 2)
        self.branch4 = nn.Conv1d(hid_channels, hid_channels, kernel_size=kernel_size[2], stride=1,
                                 padding=kernel_size[2] // 2)
        self.branch5 = nn.Conv1d(hid_channels, hid_channels, kernel_size=kernel_size[3], stride=1,
                                 padding=kernel_size[3] // 2)
        self.maxpool = nn.MaxPool1d(kernel_size=9, stride=1, padding=4)
        self.branch6 = nn.Conv1d(in_channels, hid_channels, kernel_size=1, stride=1)
        self.relu = nn.ReLU()

    def forward(self, x):
        x1 = self.relu(self.branch1(x))
        branch1 = self.relu(self.branch2(x1))
        branch2 = self.relu(self.branch3(x1))
        branch3 = self.relu(self.branch4(x1))
        branch4 = self.relu(self.branch5(x1))
        branch5 = self.branch6(self.maxpool(x))

        outputs = [branch1, branch2, branch3, branch4, branch5]
        return torch.cat(outputs, dim=1)


# Define the InSAF model as a subclass of nn.Module
class InSAF(nn.Module):
    def __init__(self, input_channels, hidden_channels, output_channels):
        super(InSAF, self).__init__()
        self.conv1 = nn.Conv1d(input_channels, hidden_channels * 5, kernel_size=1)
        self.relu = nn.ReLU()

        self.inception_block1 = InceptionBlock(in_channels=hidden_channels * 5, hid_channels=hidden_channels,
                                               kernel_size=[59, 29, 15, 7])
        self.inception_block2 = InceptionBlock(in_channels=hidden_channels * 5, hid_channels=hidden_channels,
                                               kernel_size=[59, 29, 15, 7])
        self.inception_block3 = InceptionBlock(in_channels=hidden_channels * 5, hid_channels=hidden_channels,
                                               kernel_size=[59, 29, 15, 7])
        self.self_attention1 = SelfAttention(hidden_channels * 5)

        self.inception_block4 = InceptionBlock(in_channels=hidden_channels * 5, hid_channels=hidden_channels,
                                               kernel_size=[59, 29, 15, 7])
        self.inception_block5 = InceptionBlock(in_channels=hidden_channels * 5, hid_channels=hidden_channels,
                                               kernel_size=[59, 29, 15, 7])
        self.inception_block6 = InceptionBlock(in_channels=hidden_channels * 5, hid_channels=hidden_channels,
                                               kernel_size=[59, 29, 15, 7])
        self.self_attention2 = SelfAttention(hidden_channels * 5)
        # Final convolution layer to produce the output with the specified output channels
        self.conv_final = nn.Conv1d(hidden_channels * 5, output_channels, kernel_size=1)

    def forward(self, x):

        x = self.relu(self.conv1(x))
        residual = x

        x = self.inception_block1(x)
        x = self.inception_block2(x)
        x = self.inception_block3(x)
        x = self.self_attention1(x)
        x += residual
        residual = x
        x = self.relu(x)
        x = self.inception_block4(x)
        x = self.inception_block5(x)
        x = self.inception_block6(x)
        x = self.self_attention2(x)
        x += residual
        x = self.relu(x)
        x = self.conv_final(x)
        return x

if __name__ == "__main__":
    #Date Loading##################################################################
    filepath = 'fold count2.csv'  # Specify the file path for the 2-fold simulated FDC training set, generated by FDC Simulation Model
    data_fold2 = np.array(
        pd.read_csv(filepath, header=None))  # Load the 2-fold data into a numpy array without a header
    print(data_fold2.shape)

    filepath = 'fold count3.csv'  # Specify the file path for the 3-fold simulated FDC training set, generated by FDC Simulation Model
    data_fold3 = np.array(
        pd.read_csv(filepath, header=None))  # Load the 3-fold data into a numpy array without a header
    print(data_fold3.shape)

    tran_data_fold2, label_data_fold2 = data_proceeding(data_fold2, sample_long=2000,
                                                        downsample_rate=1)  # Process fold 2 data: slicing and normalization
    tran_data_fold3, label_data_fold3 = data_proceeding(data_fold3, sample_long=2000,
                                                        downsample_rate=1)  # Process fold 3 data: slicing and normalization

    # Concatenate the data and labels from fold 2 and fold 3 to combine them into one dataset
    data_normalization_augment_all = np.concatenate((
        tran_data_fold2,
        tran_data_fold3,
    ), axis=0)

    label_normalization_augment_all = np.concatenate((
        label_data_fold2,
        label_data_fold3,
    ), axis=0)

    # Convert the combined data and labels into PyTorch tensors of float32 type for training
    train_data = torch.tensor(data_normalization_augment_all, dtype=torch.float32)  # Training data tensor
    target_data = torch.tensor(label_normalization_augment_all, dtype=torch.float32)  # Target label tensor

    print(train_data.shape)
    print(target_data.shape)

    # Create a PyTorch dataset using the training data and target labels
    dataset = torch.utils.data.TensorDataset(train_data,
                                             target_data)

    # Split the dataset into training, validation, and test sets
    train_size = int(0.9 * len(dataset))  # 90% of the dataset for training
    val_size = int(0.05 * len(dataset))  # 5% of the dataset for validation
    test_size = len(dataset) - train_size - val_size  # The remaining 5% of the dataset for testing

    # Use random_split to divide the dataset into three subsets
    train_set, val_set, test_set = random_split(dataset, [train_size, val_size, test_size])

    # Set the batch size for training, validation, and testing
    batch_size = 50  # Set the batch size for training to 50

    # Create DataLoader instances for the training, validation, and test sets
    train_loader = DataLoader(train_set, batch_size=batch_size,
                              shuffle=True)  # DataLoader for training set, shuffling data
    val_loader = DataLoader(val_set, batch_size=batch_size)  # DataLoader for validation set, no shuffling
    test_loader = DataLoader(test_set, batch_size=100)  # DataLoader for test set, with batch size of 100

    print('success')  # Print success message indicating the data loading process is complete




#InSAF Training#####################################################################
    input_channels = 2  # Number of input channels
    hidden_channels = 16  # Number of hidden channels
    output_channels = 2  # Number of output channels

    # Instantiate the model with specified input, hidden, and output channels
    model = InSAF(input_channels, hidden_channels,output_channels)

    device = device1  # Set the device (GPU or CPU) to use for model training
    model.train()  # Set the model to training mode (this enables dropout, batch norm, etc.)
    model.to(device)  # Move the model to the specified device (GPU or CPU)
    start_time = time.time()  # Record the start time of training for performance tracking
    num_epochs = 200  # Set the number of epochs for training

    # Define the loss function (Mean Squared Error Loss) and move it to the specified device
    criterion = nn.MSELoss().to(device)
    optimizer = optim.Adam(model.parameters(), lr=0.0002)  # Define the Adam optimizer with a learning rate of 0.0002

    best_val_loss = float('inf')  # Initialize the best validation loss as infinity (used for model checkpointing)
    bestmodel = None  # Placeholder for the best model (to be updated during training)
    train_loss_history = []  # List to store the training loss history for visualization
    val_loss_history = []  # List to store the validation loss history for visualization

    for epoch in range(num_epochs):  # Loop over each epoch for training

        train_loss = 0.0  # Initialize the training loss for this epoch
        for i, (data, label) in enumerate(train_loader):  # Loop over the batches in the training set
            data = data.to(device)  # Move the input data to the specified device (GPU or CPU)
            label = label.to(device)  # Move the corresponding labels to the specified device
            output = model(data)  # Pass the data through the model to get predictions
            loss = criterion(output, label)  # Compute the loss between predictions and true labels
            optimizer.zero_grad()  # Zero the gradients to prevent accumulation
            loss.backward()  # Backpropagate the loss to compute gradients
            optimizer.step()  # Update the model's parameters based on the gradients
            train_loss += loss.item()  # Add the loss for this batch to the total training loss

        avg_train_loss = train_loss / len(train_loader)  # Compute the average training loss for this epoch
        train_loss_history.append(avg_train_loss)  # Append the average training loss to the history list

        if epoch == 0:  # Only run this block on the first epoch
            end_time2 = time.time()  # Record the end time for the first epoch
            total_time = round(end_time2 - start_time)  # Calculate the total time taken for the first epoch
            formatted_time = get_formatted_time(total_time)  # Format the total time into a readable string
            print('——' * 20)
            print(f'time of one epoch: {total_time}(s),  {formatted_time}')  # Print the time taken for one epoch
            print(
                f'total time of {num_epochs} epochs: {total_time * num_epochs}(s),  {get_formatted_time(total_time * num_epochs)}')  # Print the total time for all epochs
            print('——' * 20)
            print('bestmodol_loss:', best_val_loss)  # Print the best validation loss so far
        #Model Validation for every epoch
        model.eval()  # Set the model to evaluation mode (disables dropout, batch norm, etc. for inference)
        with torch.no_grad():  # Disable gradient computation to save memory and computation during validation
            val_loss = 0.0  # Initialize the validation loss for this epoch
            for j, (data, label) in enumerate(val_loader):  # Loop through the validation data batches
                data = data.to(device)  # Move the validation data to the specified device (GPU or CPU)
                label = label.to(device)  # Move the corresponding validation labels to the specified device

                output = model(data)  # Pass the validation data through the model to get predictions

                loss = criterion(output, label)  # Compute the loss between predictions and true labels

                val_loss += loss.item()  # Add the loss for this batch to the total validation loss

            avg_val_loss = val_loss / len(val_loader)  # Compute the average validation loss for this epoch
            val_loss_history.append(avg_val_loss)  # Append the average validation loss to the history list

            if avg_val_loss < best_val_loss:  # Check if the current validation loss is better than the best validation loss so far
                best_val_loss = avg_val_loss  # Update the best validation loss
                bestmodel = model  # Store the current model as the best model
                print('Epoch [{}/{}], Train Loss: {:.8f}, Val Loss: {:.8f} ↓'
                      .format(epoch + 1, num_epochs, avg_train_loss,
                              avg_val_loss))  # Print the improved validation loss

            else:
                print('Epoch [{}/{}], Train Loss: {:.8f}, Val Loss: {:.8f}'  # Print the current epoch's losses
                      .format(epoch + 1, num_epochs, avg_train_loss, avg_val_loss))

    end_time = time.time()  # Record the end time of training
    total_time = round(end_time - start_time)  # Calculate the total time taken for training by subtracting the start time from the end time
    formatted_time = get_formatted_time(total_time)  # Format the total time into a human-readable string using a custom function

    # Print the total training time in both seconds and formatted form
    print(f'Total time: {total_time} (s), Total time: {formatted_time}')
    print(f'Best val Loss: {best_val_loss}')

    torch.save(bestmodel,"bestmodel.pt")  # Save the best model (the one with the lowest validation loss) to a file named "bestmodel.pt"


